{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Task Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "* **Difficulty level**: easy\n",
    "* **Time need to lean**: 10 minutes or less\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "output_cache": "[]"
   },
   "source": [
    "## Task options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "The following options are options to keyword `task:` and specify how tasks should be executed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "output_cache": "[]"
   },
   "source": [
    "* The resource options such as `walltime` and `cores` will be sent to individual task queues in appropriate format. You do not have to specify all options because task queues can support a subset of these options and some task queues provide default values (and some do not). It is however generally a good idea to specify them all so that your tasks could be executed on all types of task queues. \n",
    "\n",
    "* The execution options such as `workdir`, `env`, `concurrent` specify environments in which tasks will be submitted and executed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "output_cache": "[]"
   },
   "source": [
    "### Option `walltime`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "output_cache": "[]"
   },
   "source": [
    "Estimated maximum running time of the task. This parameter will be sent to different task queues and it is up to the task queue to decide if the task would be killed if the task could not be completed within specified `walltime`. `walltime` could be specified as a string in the format of `HH:MM:SS` where `HH`, `MM` and `SS` are hours, minutes, and seconds, or an integer with units `s` (second), `m` (minute), `h` (hour), or `d` (day), although the internal format of `walltime` (when you use `walltime` in `job_template` etc) is always `HH:MM:SS`. For example, you could use `walltime='240:00:00'` or `walltime='10d'` for a job that would run 10 days.\n",
    "\n",
    "It is worth noting that, if some tasks fail because of insufficient `walltime` (or `cores` or `mem`), it is safe to change these options and re-run the jobs. These will only restart the failed jobs because completed or running jobs are not affected by the change of these options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "output_cache": "[]"
   },
   "source": [
    "### Option `cores`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "output_cache": "[]"
   },
   "source": [
    "Number of cores on each computing node, which corrsponds to the `ppn` option of a PBS system.\n",
    "\n",
    "PBS task queue also accepts a parameer `nodes` (corresponds to PBS resource option `nodes`, default to 1) but it is currently unused because SoS does not yet support multi-node tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "output_cache": "[]"
   },
   "source": [
    "### Option `mem`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "output_cache": "[]"
   },
   "source": [
    "The total amount of memory needed across all nodes. Default units are bytes; can also be expressed in megabytes (`mem=4000MB`). gigabytes (`mem=4GB`) or gibibytes (`mem=4GiB`), although all inputs are converted to bytes internally. To use this option in a `job_template`, you generally need to use expressions such as `{mem//1e9}GB`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "output_cache": "[]"
   },
   "source": [
    "### Option `queue`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "output_cache": "[]"
   },
   "source": [
    "Option `queue` specifies a task queue to which the current task will be submitted. This option overrides system default (command line option `-q`) so it is generally a good idea to use command line option `-q` so that the task could be submitted to different task queues, unless the task has to be executed in a particular server (e.g. with a software that is unavailable elsewhere)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Option `to_host`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Option `to_host` specifies additional files or directories that would be synchronized to the remote host before tasks are executed. It can be specified as\n",
    "\n",
    "* A single file or directory (with respect to local file system), or\n",
    "* A list of files or directories, or\n",
    "* A dictinary of `{local: remote}` file maps that specify how local files are synchronized to the remote host.\n",
    "\n",
    "In the first two cases, the files or directories will be translated using the host-specific path maps. In the last case, the `remote` path (that should be relative to the remote file system) will be used without translating `local` file.\n",
    "\n",
    "Note that \n",
    "1. If a symbolic link is specified in `to_host`, both the symbolic link and the path it refers to would be synchronized to the remote host.\n",
    "2. If the task is executed on the local host (remote host coincide with local host), `to_host` is usually ignored unless it is specified in the third dictionary format, which copies files to another location before task execution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Option `from_host`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Option `from_host` specifies additional files or directories that would be synchronized from the remote host after tasks are executed. It can be specified as\n",
    "\n",
    "* A single file or directory (with respect to local file system), or\n",
    "* A list of files or directories, or\n",
    "* A dictinary of `{local: remote}` file maps that specify how local files are synchronized from the remote host.\n",
    "\n",
    "In the first two cases, the files or directories will be translated using the host-specific path maps to determine what remote files to retrieve. In the last case, the `remote` path (that should be relative to the remote file system) will be used without path translation. If the task is executed on the local host (remote host coincide with local host), this option is usually ignored unless it is specified in the third dictionary format, which copies files to another location after the task is executed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "output_cache": "[]"
   },
   "source": [
    "### Option `map_vars`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "output_cache": "[]"
   },
   "source": [
    "In addition to `input` (`_input`), `output` (`_output`), `depends` (`_depends`) that are defined implicitly by `input:`, `output:` and `depends:` statements, you can specify additional variables that will be translated from local to remote host. This option accepts paths int he format of `str` or sequence (`list`, `tuple`, `set` etc) of `str` and will be mapped to variable of the same type (with paths replaced by remote paths on remote host). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Option `trunk_size`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Options `trunk_size` and `trunk_workers` are useful for dividing a large number of small tasks into several larger tasks so that they can be executed efficiently on a cluster system.\n",
    "\n",
    "Option `trunk_size` groups concurrent tasks into trunks of specified size. For example, if you need to run 10000 simulations that each lasts about 1 minute, you can group the tasks into `10`  umbrella tasks, each running `1000` simulations.\n",
    "\n",
    "```\n",
    "[10]\n",
    "import random\n",
    "input: for_each={'seed': [random.randint(1, 10000000) for x in range(10000)]}\n",
    "task: mem=`1G`, walltime='1m', cores=2, trunk_size=1000\n",
    "sh: expand=True\n",
    "    run_simulation --seed (seed) >> res_{seed}.res\n",
    "```\n",
    "\n",
    "The unbrella tasks have the following properties:\n",
    "1. Tasks embedded by an umbrella task are executed normally in the sense that they have their own input, output, task ID, signatures etc, although only the umbrella tasks are visible to task engines.\n",
    "2. Umbrella task IDs are prefixed by `M#_` where `#` is the number of embedded tasks.\n",
    "3. Umbrella tasks adjust resource options such as `walltime` automatically so in the above example, each umbrella task will have `walltime='16:40:00'` (1000 minutes). \n",
    "4. Option `name` (job name on PBS systems) will be adjusted to `{name)_##` (e.g. `default_10_6000_1000` if default `name='{step_name}_{_index}'` is used) where `##` is the number of subtasks.\n",
    "5. The entire umbrella will fail if any of the subtasks fails. However, since each subtask has its own signature, completed tasks will be ignored when you rerun the umbrella task (unless `-s force` is specified to forcefully re-execute all tasks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "sos"
   },
   "source": [
    "### Option `trunk_workers`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Option `trunk_workers` specifies number of workers for umbrella tasks. If this option is specified, an umbrella task will be executed by a master process that dispatches embedded tasks to `trunk_workers` workers. Using the same simulation example with `trunk_workers=5`,\n",
    "\n",
    "```\n",
    "import random\n",
    "input: for_each={'seed': [random.randint(1, 10000000) for x in range(10000)]}\n",
    "task: mem=`1G`, walltime='1m', cores=2, trunk_size=1000, trunk_workers=5\n",
    "sh: expand=True\n",
    "    run_simulation --seed (seed) >> res_{seed}.res\n",
    "```\n",
    "\n",
    "* There would be `10000 / 1000 = 10` umbrealla tasks each with `1000` (`trunk_size`) subtasks.\n",
    "* Each umbrella task would use `2 * 5 + 1 = 11` cores where the extra core is used by the master process.\n",
    "* Each umbrella task would use 5G of RAM (`5 * 1G`).\n",
    "* Each umbrella task would have a `walltime` of `1000 / 5 * 1 = 200` minutes (`walltime='03:20:00'`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Option `workdir`\n",
    "\n",
    "Default to current working directory.\n",
    "\n",
    "Option `workdir` controls the working directory of the task. For example, the following step downloads a file to the `resource_dir` using command `wget`.\n",
    "\n",
    "```python\n",
    "[10]\n",
    "\n",
    "task: workdir=resource_dir\n",
    "\n",
    "run:\n",
    "  wget a_url -O filename\n",
    "```\n",
    "\n",
    "Runtime option `workdir` will be translated to remote host if the task is executed remotely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Option `concurrent`\n",
    "\n",
    "Default to `True`.\n",
    "\n",
    "If the step process is repeated for multiple substeps (using input options `group_by` or `for_each`), all loop processes will by default be sent to the task engine to be executed in parallel (subject to `max_running_jobs` of individual task queue). If your tasks are sequential in nature (e.g. the next substep depends on the result of the current substep), you can set `concurrent=False`, in which case the next task will be generated and sent to the task queue only after the current one has been completed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Option `shared`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "SoS tasks are executed externally and by default does not return any value. Similar to the `shared` step option (that passes step variables to the workflow), you can use `shared` option to pass task variables to the step in which the task is defined.\n",
    "\n",
    "For example, the following script perform some simulations in 10 tasks and return the result by variable `rng`, which is then shared to the workflow by step option `shared` so that it can be available to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">10 tasks completed: <a onclick=\"task_info('a190034a4845df90', 'laptop')\">a190</a>, <a onclick=\"task_info('c3dc90b99a30eef3', 'laptop')\">c3dc</a>, ..., <a onclick=\"task_info('e346404fd41fa97b', 'laptop')\">e346</a></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "524\n",
      "[129, 479, 825, 773, 453, 923, 459, 257, 676, 524]\n"
     ]
    }
   ],
   "source": [
    "%run\n",
    "[10 (simulate): shared=['rng', 'step_rng']]\n",
    "input: for_each={'i': range(10)}\n",
    "task: shared='rng'\n",
    "print(f\"{i}\")\n",
    "import random\n",
    "rng = random.randint(1, 1000)\n",
    "\n",
    "[20]\n",
    "print(rng)\n",
    "print(step_rng)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "sos"
   },
   "source": [
    "It is important to note that option `shared` of the task passes variable `rng` to substeps of the step. The step level `shared='rng'` will only return `rng` of the last substep, and `shared='step_rng'` will return `rng` from all substeps as a list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "sos"
   },
   "source": [
    "Also similar to step option `shared`, task option `shared` accepts a single variable (e.g. `rng`), a sequence of variables  (e.g. `('rng', 'sum')`), a dictionary of variable derived from an expression (e.g. `{'result': 'float(open(output).read())'}`, or sequences of names and variables. In the dictionary case, the values of the dictionary should be an expression (string), that will be evaluated upon the completion of the task, and assign to the specified variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "sos"
   },
   "source": [
    "### Option `env`\n",
    "\n",
    "The `env` option allow you to modify runtime environment, similar to the `env` parameter of the `subprocess.Popen` function. For example, you can execute your command with in a specific directory using\n",
    "\n",
    "```sos\n",
    "task:  env={'PATH': '/path/to/mycommand' + os.sep + os.environ['PATH']}\n",
    "run:\n",
    "   mycommand \n",
    "```\n",
    "\n",
    "Option `env` is NOT translated to remote host because it is of type directionay. The job template is usually a good place to set host-specific environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "sos"
   },
   "source": [
    "### Option `prepend_path`\n",
    "\n",
    "Option `prepend_path` is a shortcut to option `env` to prepend one (a string) or more (a list of strings) paths to system path. For example, the above example can be shortened to\n",
    "\n",
    "```sos\n",
    "task:  prepend_path='/path/to/mycommand'\n",
    "run:\n",
    "   mycommand \n",
    "```\n",
    "\n",
    "Option `prepend_path` is NOT translated to remote host because it is likely to be host specific."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "sos",
    "output_cache": "[]"
   },
   "source": [
    "### Option `active`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "sos",
    "output_cache": "[]"
   },
   "source": [
    "Option `active` specifies the active task within a input loop. It can be `True` (default), or `False` (or a condition that returns `True` or `False`), or an index or a list of indexes when the task will be executed. Negative index is acceptable (e.g. task for only the last input loop will be executed with `active=-1`).\n",
    "\n",
    "For example, `task` in the following example is not executed because `a.txt` already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">> a.txt (6 B):</div>"
      ],
      "text/plain": [
       "\n",
       "> a.txt (6 B):"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "%preview -n a.txt\n",
    "!echo \"hello\" > a.txt\n",
    "\n",
    "task: active=not path('a.txt').exists()\n",
    "sh:\n",
    "    echo \"Task executed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Option `tags`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "By default, a task is tagged by step name and workflow ID so that tasks from the same step and/or workflow could be targetted with option `--tags` for commands such as `sos status`, `sos kill`, and `sos purge`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "You can specify additional tags to tasks using option `tags`. A tag can contain alphabetic and numeric characters, dash (`-`), underscore (`_`), and dot (`.`). Tags with other characters will still be accepted but with non-comforming characters removed.\n",
    "\n",
    "For example, if each task handles a sample with an ID, you can use\n",
    "\n",
    "```\n",
    "input: for_each={'ID': IDs}\n",
    "task: tags=ID\n",
    "```\n",
    "to add sample IDs to task tags, or use \n",
    "\n",
    "```\n",
    "input: input_files, paired_with=['IDs', 'barcode']\n",
    "task: tags=[_ID, _barcode, 'my_cmd']\n",
    "sh:\n",
    "    my_cmd ...\n",
    "```\n",
    "to tag tasks with sample ID, barcode, and command to each task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Further reading\n",
    "\n",
    "* "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF"
    ],
    [
     "R",
     "ir",
     "R",
     "#DCDCDA"
    ],
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0
   },
   "version": "0.17.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
